{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dsnkWbcccROTjbtJnHKXHHAnZXxaQ5WE","timestamp":1766827314665}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from transformers import BertForQuestionAnswering, BertTokenizer\n","\n","# Load model and tokenizer\n","model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForQuestionAnswering.from_pretrained(model_name)\n","\n","# Function to get answer\n","def get_answer(question, context):\n","    inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True, max_length=512)\n","    input_ids = inputs['input_ids']\n","    attention_mask = inputs['attention_mask']\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        start_logits = outputs.start_logits\n","        end_logits = outputs.end_logits\n","\n","    # Get the most likely beginning and end of answer\n","    start_index = torch.argmax(start_logits)\n","    end_index = torch.argmax(end_logits) + 1\n","\n","    # Convert tokens to answer string\n","    answer_ids = input_ids[0][start_index:end_index]\n","    answer = tokenizer.decode(answer_ids, skip_special_tokens=True)\n","    return answer\n","\n","\n"],"metadata":{"id":"qnVUURIovNMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Main interaction\n","context = input(\"Enter context: \")\n"],"metadata":{"id":"u1Yipklpvbuu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question = input(\"Enter your question: \")\n","answer = get_answer(question, context)\n","print(\"\\nAnswer:\", answer)"],"metadata":{"id":"wSTfaSTLyDbE"},"execution_count":null,"outputs":[]}]}